#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è°ƒè¯•è·¯ç”±é€‰æ‹©å™¨çš„ç®€åŒ–è„šæœ¬
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import sys
import os
import csv
import time

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# æ¨¡æ‹Ÿé…ç½®
config = {
    'hidden_size': 256,
    'past_len': 20,
    'num_map_feature': 29,
    'num_agent_feature': 39,
    'num_queries_enc': 192,
    'num_queries_dec': 12,
    'max_num_roads': 32,
    'max_num_agents': 32,
    'num_experts': 2,
    'learning_rate': 0.001,
    'learning_rate_sched': [10, 20, 30],
    'train_router_only': True,
    'method': {
        'model_name': 'MOE'
    }
}

def create_dummy_batch(batch_size=4):
    """åˆ›å»ºæ¨¡æ‹Ÿæ‰¹æ¬¡æ•°æ®"""
    input_dict = {
        'obj_trajs': torch.randn(batch_size, 32, 20, 39),
        'obj_trajs_mask': torch.ones(batch_size, 32, 20),
        'map_polylines': torch.randn(batch_size, 32, 20, 29),
        'map_polylines_mask': torch.ones(batch_size, 32, 20),
        'track_index_to_predict': torch.randint(0, 32, (batch_size,)),
        'center_gt_trajs': torch.randn(batch_size, 60, 4),
        'center_gt_trajs_mask': torch.ones(batch_size, 60),
        'center_gt_final_valid_idx': torch.randint(0, 60, (batch_size,)),
        'scenario_id': ['scenario_{}'.format(i) for i in range(batch_size)],
        'center_objects_world': torch.randn(batch_size, 7),
        'center_objects_id': torch.randint(0, 1000, (batch_size,)),
        'center_objects_type': torch.randint(1, 4, (batch_size,)),
        'map_center': torch.randn(batch_size, 2),
        'center_gt_trajs_src': torch.randn(batch_size, 60, 4),
        'dataset_name': ['test'] * batch_size,
        'kalman_difficulty': torch.randint(0, 90, (batch_size, 3)),
        'trajectory_type': torch.randint(0, 8, (batch_size,)),
    }
    
    batch = {
        'input_dict': input_dict,
        'batch_size': batch_size
    }
    
    return batch

class SimpleExpert(nn.Module):
    """ç®€åŒ–çš„ä¸“å®¶æ¨¡å‹ï¼Œç”¨äºè°ƒè¯•"""
    def __init__(self, input_size=39, hidden_size=256, output_size=5):
        super(SimpleExpert, self).__init__()
        self.network = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, output_size)
        )
    
    def forward(self, batch):
        # ç®€åŒ–çš„å‰å‘ä¼ æ’­
        input_dict = batch['input_dict']
        obj_trajs = input_dict['obj_trajs']
        batch_size, num_agents, seq_len, features = obj_trajs.shape
        
        # ç®€å•å¤„ç†è¾“å…¥
        x = obj_trajs.view(batch_size, -1)
        output = self.network(x)
        
        # æ„é€ é¢„æµ‹è¾“å‡º
        predicted_trajectory = torch.randn(batch_size, 6, 60, 5)  # (batch, modes, time, features)
        predicted_probability = torch.softmax(torch.randn(batch_size, 6), dim=1)  # (batch, modes)
        
        prediction = {
            'predicted_trajectory': predicted_trajectory,
            'predicted_probability': predicted_probability
        }
        
        # ç®€å•æŸå¤±è®¡ç®—
        loss = torch.mean(output ** 2)
        
        return prediction, loss

def load_balance_loss(routing_probs):
    """è®¡ç®—è´Ÿè½½å¹³è¡¡æŸå¤±"""
    expert_mean = routing_probs.mean(dim=0)
    loss = (expert_mean * routing_probs.sum(dim=0)).sum() / routing_probs.size(0)
    return loss

def train_router_only(num_epochs=10, batch_size=4):
    """åªè®­ç»ƒè·¯ç”±é€‰æ‹©å™¨"""
    print("Starting Router-only Training...")
    
    # å¯¼å…¥è·¯ç”±é€‰æ‹©å™¨
    from moe import TrajAttentionRouter
    
    # åˆ›å»ºè·¯ç”±é€‰æ‹©å™¨
    router = TrajAttentionRouter(config)
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = optim.Adam(router.parameters(), lr=config['learning_rate'])
    
    # åˆ›å»ºæ¨¡æ‹Ÿä¸“å®¶
    expert1 = SimpleExpert()
    expert2 = SimpleExpert()
    
    # åˆ›å»ºæ—¥å¿—æ–‡ä»¶
    log_file = 'router_training_log.csv'
    with open(log_file, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['epoch', 'batch', 'total_loss', 'routing_loss', 'lb_loss', 'routing_probs'])
    
    # è®­ç»ƒå¾ªç¯
    for epoch in range(num_epochs):
        epoch_loss = 0.0
        num_batches = 5  # æ¯ä¸ªepochçš„æ‰¹æ¬¡æ•°é‡
        
        for batch_idx in range(num_batches):
            # åˆ›å»ºæ‰¹æ¬¡æ•°æ®
            batch = create_dummy_batch(batch_size)
            
            # æ¸…é›¶æ¢¯åº¦
            optimizer.zero_grad()
            
            # è·¯ç”±é€‰æ‹©å™¨å‰å‘ä¼ æ’­
            routing_probs = router(batch)
            
            # æ¨¡æ‹Ÿä¸“å®¶æŸå¤± (è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨å›ºå®šçš„ç›®æ ‡æŸå¤±æ¥æµ‹è¯•è·¯ç”±æ˜¯å¦èƒ½å­¦ä¹ )
            # å‡è®¾ä¸“å®¶1åœ¨å½“å‰æ‰¹æ¬¡ä¸Šè¡¨ç°æ›´å¥½ï¼Œè·¯ç”±åº”è¯¥å­¦ä¼šé€‰æ‹©ä¸“å®¶1
            expert1_loss = torch.tensor(1.5)  # è¾ƒå¥½çš„æŸå¤±
            expert2_loss = torch.tensor(3.0)  # è¾ƒå·®çš„æŸå¤±
            
            # æ ¹æ®è·¯ç”±æ¦‚ç‡è®¡ç®—åŠ æƒæŸå¤±
            weighted_loss = (routing_probs[:, 0] * expert1_loss + routing_probs[:, 1] * expert2_loss).mean()
            
            # è®¡ç®—è´Ÿè½½å¹³è¡¡æŸå¤±
            lb_loss_val = load_balance_loss(routing_probs)
            lb_loss_weight = 0.01
            
            # æ€»æŸå¤±
            total_loss = weighted_loss + lb_loss_weight * lb_loss_val
            
            # åå‘ä¼ æ’­
            total_loss.backward()
            
            # æ›´æ–°å‚æ•°
            optimizer.step()
            
            # ç´¯è®¡æŸå¤±
            epoch_loss += total_loss.item()
            
            # è®°å½•æ—¥å¿—
            with open(log_file, 'a', newline='') as f:
                writer = csv.writer(f)
                writer.writerow([
                    epoch, 
                    batch_idx, 
                    total_loss.item(), 
                    weighted_loss.item(), 
                    lb_loss_val.item(),
                    routing_probs.detach().cpu().numpy().tolist()
                ])
            
            # æ‰“å°è¿›åº¦
            if batch_idx % 2 == 0:
                print(f"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{num_batches}], "
                      f"Loss: {total_loss.item():.4f}, Routing: {routing_probs.mean(dim=0).detach().cpu().numpy()}")
        
        avg_loss = epoch_loss / num_batches
        print(f"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}")
        
        # æ‰“å°å½“å‰è·¯ç”±æ¦‚ç‡åˆ†å¸ƒ
        dummy_batch = create_dummy_batch(100)  # æ›´å¤§çš„æ‰¹æ¬¡æ¥è§‚å¯Ÿå¹³å‡è¡Œä¸º
        with torch.no_grad():
            routing_probs = router(dummy_batch)
            mean_probs = routing_probs.mean(dim=0)
            print(f"Average routing probabilities: {mean_probs.cpu().numpy()}")
    
    print("Training completed!")
    print(f"Log saved to {log_file}")

def test_router_convergence():
    """æµ‹è¯•è·¯ç”±é€‰æ‹©å™¨æ˜¯å¦èƒ½æ”¶æ•›åˆ°æ­£ç¡®çš„ä¸“å®¶é€‰æ‹©"""
    print("\nTesting Router Convergence...")
    
    # å¯¼å…¥è·¯ç”±é€‰æ‹©å™¨
    from moe import TrajAttentionRouter
    
    # åˆ›å»ºè·¯ç”±é€‰æ‹©å™¨
    router = TrajAttentionRouter(config)
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = optim.Adam(router.parameters(), lr=0.01)
    
    # åˆ›å»ºå›ºå®šçš„ç›®æ ‡è·¯ç”±æ¦‚ç‡ (ä¾‹å¦‚ï¼šæ€»æ˜¯é€‰æ‹©ä¸“å®¶1)
    target_probs = torch.tensor([[1.0, 0.0]])  # æ€»æ˜¯é€‰æ‹©ä¸“å®¶1
    
    # è®­ç»ƒè·¯ç”±é€‰æ‹©å™¨æ¥åŒ¹é…ç›®æ ‡æ¦‚ç‡
    print("Training router to match target probabilities...")
    
    for epoch in range(100):
        optimizer.zero_grad()
        
        # åˆ›å»ºæ‰¹æ¬¡æ•°æ®
        batch = create_dummy_batch(16)
        
        # è·¯ç”±é€‰æ‹©å™¨å‰å‘ä¼ æ’­
        routing_probs = router(batch)
        
        # è®¡ç®—ä¸ç›®æ ‡æ¦‚ç‡çš„KLæ•£åº¦æŸå¤±
        target_expanded = target_probs.expand(routing_probs.shape[0], -1)
        kl_loss = torch.nn.functional.kl_div(
            torch.log(routing_probs + 1e-8), 
            target_expanded, 
            reduction='batchmean'
        )
        
        # åå‘ä¼ æ’­
        kl_loss.backward()
        
        # æ›´æ–°å‚æ•°
        optimizer.step()
        
        # æ‰“å°è¿›åº¦
        if epoch % 20 == 0:
            mean_probs = routing_probs.mean(dim=0)
            print(f"Epoch {epoch}, KL Loss: {kl_loss.item():.4f}, "
                  f"Mean routing probs: {mean_probs.detach().cpu().numpy()}")
    
    # æœ€ç»ˆæµ‹è¯•
    batch = create_dummy_batch(100)
    with torch.no_grad():
        routing_probs = router(batch)
        mean_probs = routing_probs.mean(dim=0)
        print(f"Final mean routing probabilities: {mean_probs.cpu().numpy()}")
        
        # æ£€æŸ¥æ˜¯å¦æ”¶æ•›
        if mean_probs[0] > 0.8:
            print("âœ… Router successfully converged to target distribution!")
        else:
            print("âš ï¸ Router did not converge properly.")

if __name__ == "__main__":
    print("Debugging MOE Router...")
    print("=" * 50)
    
    # æµ‹è¯•è·¯ç”±è®­ç»ƒ
    train_router_only(num_epochs=5)
    
    # æµ‹è¯•è·¯ç”±æ”¶æ•›æ€§
    test_router_convergence()
    
    print("\n" + "=" * 50)
    print("ğŸ‰ Debugging completed!")